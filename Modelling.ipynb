{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Modelling.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"id":"28cNFoz9YCoD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652232003068,"user_tz":-420,"elapsed":3811,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"e67fb1f1-c1f4-43f7-f4ef-f63a002a2db2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# reference\n","# https://confusedcoders.com/data-science/deep-learning/how-to-build-deep-neural-network-for-custom-ner-with-keras\n","# https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n","# https://www.aitimejournal.com/@akshay.chavan/complete-tutorial-on-named-entity-recognition-ner-using-python-and-keras"],"metadata":{"id":"Tf_Z5-HgYHbC","executionInfo":{"status":"ok","timestamp":1652232003068,"user_tz":-420,"elapsed":4,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow tensorflow_text pandas numpy tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWEx_jqbZBx3","executionInfo":{"status":"ok","timestamp":1652232006020,"user_tz":-420,"elapsed":2955,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"191fa1dc-5955-4470-d43b-10b82d2fd15c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.8.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import tensorflow_text as tf_text\n","import tensorflow as tf\n","# import tensorflow_addons as tfa\n","import numpy as np\n","from tqdm import tqdm\n","import sklearn.model_selection"],"metadata":{"id":"2ulTtP5gYgZo","executionInfo":{"status":"ok","timestamp":1652232008188,"user_tz":-420,"elapsed":1,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# MODEL PARAMS\n","vocab_size = 25000\n","sequence_length = 256"],"metadata":{"id":"5DoToffIbu16","executionInfo":{"status":"ok","timestamp":1652232345089,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Load Data and Prepare"],"metadata":{"id":"rTHXYA67ZGbF"}},{"cell_type":"code","source":["from typing import List\n","\n","def tag_normalize(x: List[int]):\n","  # This will pad the tag to the sequence length\n","  # If the original tag is more than sequence length, it will be turnicate\n","  if len(x) > sequence_length:\n","    return x[:256]\n","  \n","  differences = sequence_length - len(x)\n","  zero_pad = [0 for _ in range(differences)]\n","  x = x + zero_pad\n","  return x"],"metadata":{"id":"Nyk9_am5ddhq","executionInfo":{"status":"ok","timestamp":1652232347515,"user_tz":-420,"elapsed":3,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["!gdown 1piwUH_CpsYyqwpLWQKo5UTnvZk8NlYMG"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHdNPCyd6IzK","executionInfo":{"status":"ok","timestamp":1652232350750,"user_tz":-420,"elapsed":3237,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"850f40df-145c-47c2-e019-6f480804f0ed"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1piwUH_CpsYyqwpLWQKo5UTnvZk8NlYMG\n","To: /content/ner_location.csv\n","\r  0% 0.00/6.54M [00:00<?, ?B/s]\r100% 6.54M/6.54M [00:00<00:00, 322MB/s]\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/ner_location.csv\")\n","df['word'] = df['word'].apply(eval) # we need to do this, because we stored this as a list\n","df['tag'] = df['tag'].apply(eval) # we need to do this, because we stored this as a list\n","df[\"sentence\"] = df['word'].apply(lambda x: \" \".join(x))\n","df[\"tag_normal\"] = df['tag'].apply(tag_normalize)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"Nch2NISeYmex","executionInfo":{"status":"ok","timestamp":1652232353171,"user_tz":-420,"elapsed":2422,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"2b7fb604-85c3-442c-e12a-4f0e95d32769"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    word  \\\n","0      [thousands, of, demonstrators, have, marched, ...   \n","1      [helicopter, gunships, saturday, pounded, mili...   \n","2      [un, relief, coordinator, jan, egeland, said, ...   \n","3      [mr, egeland, said, the, latest, figures, show...   \n","4      [he, said, last, week, s, tsunami, and, the, m...   \n","...                                                  ...   \n","24404  [in, an, opinion, piece, in, the, washington, ...   \n","24405  [president, bush, last, week, confirmed, he, s...   \n","24406  [iran, s, elite, security, forces, are, warnin...   \n","24407  [opposition, activists, have, called, for, pro...   \n","24408  [following, iran, s, disputed, june, elections...   \n","\n","                                                     tag  \\\n","0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n","1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n","2      [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n","3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","...                                                  ...   \n","24404  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24405  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24406  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24407  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24408  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","                                                sentence  \\\n","0      thousands of demonstrators have marched throug...   \n","1      helicopter gunships saturday pounded militant ...   \n","2      un relief coordinator jan egeland said sunday ...   \n","3      mr egeland said the latest figures show millio...   \n","4      he said last week s tsunami and the massive un...   \n","...                                                  ...   \n","24404  in an opinion piece in the washington post fri...   \n","24405  president bush last week confirmed he secretly...   \n","24406  iran s elite security forces are warning oppos...   \n","24407  opposition activists have called for protests ...   \n","24408  following iran s disputed june elections right...   \n","\n","                                              tag_normal  \n","0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n","1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n","2      [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n","3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","...                                                  ...  \n","24404  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24405  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24406  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24407  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24408  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","\n","[24409 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-aae61a3c-9ae4-42a2-a83d-6b784e6d1ff7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>tag</th>\n","      <th>sentence</th>\n","      <th>tag_normal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[thousands, of, demonstrators, have, marched, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n","      <td>thousands of demonstrators have marched throug...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[helicopter, gunships, saturday, pounded, mili...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>helicopter gunships saturday pounded militant ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[un, relief, coordinator, jan, egeland, said, ...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>un relief coordinator jan egeland said sunday ...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[mr, egeland, said, the, latest, figures, show...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>mr egeland said the latest figures show millio...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[he, said, last, week, s, tsunami, and, the, m...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>he said last week s tsunami and the massive un...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24404</th>\n","      <td>[in, an, opinion, piece, in, the, washington, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>in an opinion piece in the washington post fri...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24405</th>\n","      <td>[president, bush, last, week, confirmed, he, s...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>president bush last week confirmed he secretly...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24406</th>\n","      <td>[iran, s, elite, security, forces, are, warnin...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>iran s elite security forces are warning oppos...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24407</th>\n","      <td>[opposition, activists, have, called, for, pro...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>opposition activists have called for protests ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24408</th>\n","      <td>[following, iran, s, disputed, june, elections...</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>following iran s disputed june elections right...</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>24409 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aae61a3c-9ae4-42a2-a83d-6b784e6d1ff7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aae61a3c-9ae4-42a2-a83d-6b784e6d1ff7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aae61a3c-9ae4-42a2-a83d-6b784e6d1ff7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# Sanity check on tag_normal\n","for i in range(len(df)):\n","  interest = df[\"tag_normal\"].iloc[i]\n","  if len(interest) != sequence_length:\n","    print(f\"Found wrong length on {i}\")"],"metadata":{"id":"_0s4umoGf0WN","executionInfo":{"status":"ok","timestamp":1652232353172,"user_tz":-420,"elapsed":6,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Combine all words into one corpus\n","CORPUS = \" \".join(df[\"sentence\"])"],"metadata":{"id":"GSf5luN2bJCx","executionInfo":{"status":"ok","timestamp":1652232353172,"user_tz":-420,"elapsed":6,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["a = df[\"word\"].to_list()\n","b = df[\"tag\"].to_list()\n","word_combine = [j for i in a for j in i]\n","tag_combine = [j for i in b for j in i]\n","print(len(word_combine))\n","print(len(tag_combine))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFRp2ZwIoZyB","executionInfo":{"status":"ok","timestamp":1652232353172,"user_tz":-420,"elapsed":6,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"1e884d74-6eef-42d8-f02f-d35fa0fa7e99"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["527146\n","527146\n"]}]},{"cell_type":"markdown","source":["Create Text Vectorizer Layer (Preprocessing Layer)   \n","This convert raw strings into number"],"metadata":{"id":"khZZbdOOb8EH"}},{"cell_type":"code","source":["tf.keras.backend.clear_session()"],"metadata":{"id":"JsSmmCu3jwUB","executionInfo":{"status":"ok","timestamp":1652232353825,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["vectorize_layer = tf.keras.layers.TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)"],"metadata":{"id":"yYYrzIzzb51C","executionInfo":{"status":"ok","timestamp":1652232356851,"user_tz":-420,"elapsed":3027,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["vectorize_layer.adapt([CORPUS])"],"metadata":{"id":"-glityUZcPAX","executionInfo":{"status":"ok","timestamp":1652232360669,"user_tz":-420,"elapsed":524,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["example = df['sentence'].iloc[1]\n","print(f\"Example: {example}\")\n","print(vectorize_layer(example))\n","print(np.array(df['tag_normal'].iloc[1]).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxzHOHWycXPo","executionInfo":{"status":"ok","timestamp":1652232360669,"user_tz":-420,"elapsed":3,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"eecf3421-bce3-4f5e-ea3b-ab2fd029a13e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Example: helicopter gunships saturday pounded militant hideouts in the orakzai tribal region where many taliban militants are believed to have fled to avoid an earlier military offensive in nearby south waziristan\n","tf.Tensor(\n","[1067 4236   98 3554  254 3774    3    2 2779  556  119  149  313  408\n","  105   33  741    5   16  786    5 1538   21  140   44  565    3 1218\n","   75  869    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0], shape=(256,), dtype=int64)\n","(256,)\n"]}]},{"cell_type":"markdown","source":["Modelling  \n","1. Text Vectorizer\n","2. Embedding\n","3. BiLSTM\n","4. LSTM\n","5. Dense (sequence_length)"],"metadata":{"id":"W2M4WDbzjlLi"}},{"cell_type":"code","source":["def create_model(train: bool):\n","  input = tf.keras.layers.Input(shape=(1), dtype=tf.string)\n","  x = vectorize_layer(input)\n","  x = tf.keras.layers.Embedding(vocab_size, 256)(x)\n","  x = tf.keras.layers.Dropout(0.5)(x, training=train)\n","  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True), merge_mode = 'concat')(x)\n","  x = tf.keras.layers.BatchNormalization()(x, training=train)\n","  x = tf.keras.layers.Dropout(0.3)(x, training=train)\n","  x = tf.keras.layers.LSTM(256, return_sequences=True)(x)\n","  x = tf.keras.layers.BatchNormalization()(x, training=train)\n","  x = tf.keras.layers.Dropout(0.3)(x, training=train)\n","  output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2, activation=\"softmax\", kernel_initializer='he_normal'))(x)\n","\n","  model = tf.keras.Model(input, output)\n","  optimizer = tf.keras.optimizers.Adam()\n","  loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n","  return model, optimizer, loss_func\n","\n","model, optimizer, loss_func = create_model(True)"],"metadata":{"id":"CidKYKJKjztg","executionInfo":{"status":"ok","timestamp":1652232368179,"user_tz":-420,"elapsed":1228,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3utn0ldj9uA","executionInfo":{"status":"ok","timestamp":1652232375708,"user_tz":-420,"elapsed":523,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"6c069155-7150-4cbc-f561-f2d9217fb573"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization (TextVec  (None, 256)              0         \n"," torization)                                                     \n","                                                                 \n"," embedding (Embedding)       (None, 256, 256)          6400000   \n","                                                                 \n"," dropout (Dropout)           (None, 256, 256)          0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 256, 512)         1050624   \n"," l)                                                              \n","                                                                 \n"," batch_normalization (BatchN  (None, 256, 512)         2048      \n"," ormalization)                                                   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256, 512)          0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 256, 256)          787456    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 256, 256)         1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256, 256)          0         \n","                                                                 \n"," time_distributed (TimeDistr  (None, 256, 2)           514       \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 8,241,666\n","Trainable params: 8,240,130\n","Non-trainable params: 1,536\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Train"],"metadata":{"id":"-AtzIwojvNsM"}},{"cell_type":"code","source":["batch_size = 64 # Every 32 data we train it\n","epochs = 3"],"metadata":{"id":"ybJyeDmTvWQL","executionInfo":{"status":"ok","timestamp":1652232382916,"user_tz":-420,"elapsed":522,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["for i in range(1):\n","  print(f\"Epochs: {i}\")\n","  # Sliding window\n","  num_word = len(word_combine)\n","  \n","  x_batch = []\n","  y_batch = []\n","\n","  p_bar = tqdm(range(num_word - (num_word % sequence_length + sequence_length)))\n","  for j in p_bar:\n","    start_idx = j\n","    end_idx = j + sequence_length\n","\n","    x_prepare = word_combine[start_idx : end_idx] \n","    y_prepare = tag_combine[start_idx : end_idx] \n","\n","    x_batch.append(\" \".join(x_prepare))\n","    y_batch.append(y_prepare)\n","\n","    if len(x_batch) % batch_size == 0:\n","      x_feed = tf.convert_to_tensor(x_batch)\n","      y_feed = tf.convert_to_tensor(y_batch)\n","      \n","      with tf.GradientTape() as tape:\n","        # Forward pass\n","        y_pred = model(x_feed)\n","\n","        loss = loss_func(y_feed, y_pred)\n","        pred = tf.math.argmax(y_pred, axis=2)\n","        acc = tf.reduce_mean(tf.keras.metrics.binary_accuracy(y_feed, tf.cast(pred, dtype=tf.int32)))\n","\n","      p_bar.set_postfix({\n","          \"loss\" : loss,\n","          \"acc\": acc\n","      })\n","      \n","      # Backprop\n","      grad = tape.gradient(loss, model.trainable_weights)\n","      optimizer.apply_gradients(zip(grad, model.trainable_weights))\n","\n","      x_batch = []\n","      y_batch = []"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6ABfPHDvsts","executionInfo":{"status":"ok","timestamp":1652233377490,"user_tz":-420,"elapsed":989648,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"outputId":"8867b4fc-cf16-4842-9850-a70bfc4be2ee"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Epochs: 0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 526848/526848 [16:29<00:00, 532.21it/s, loss=tf.Tensor(0.099455036, shape=(), dtype=float32), acc=tf.Tensor(0.96429443, shape=(), dtype=float32)]\n"]}]},{"cell_type":"code","source":["# Transfer weight\n","new_model, _, _ = create_model(False)\n","\n","new_model.set_weights(model.get_weights())"],"metadata":{"id":"ICU93fTF6wfQ","executionInfo":{"status":"ok","timestamp":1652233383038,"user_tz":-420,"elapsed":1221,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["text = \"hotel in bali\""],"metadata":{"id":"UbIley9J09m-","executionInfo":{"status":"ok","timestamp":1652234259417,"user_tz":-420,"elapsed":738,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["prediction = new_model.predict([text])[0]\n","pred_converted = tf.math.argmax(prediction, axis=1)\n","def get_idx(prediction):\n","  idx = []\n","  for i in range(len(prediction)):\n","    if prediction[i] == 1:\n","      idx.append(i)\n","\n","  return idx\n","\n","index_one = get_idx(pred_converted)\n","\n","text_vectorizator = new_model.get_layer(\"text_vectorization\")\n","dictionary = text_vectorizator.get_vocabulary()\n","vectorized = text_vectorizator([text])[0]\n","attention = []\n","for i in index_one:\n","  attention.append(vectorized[i])\n","for i in attention:\n","  print(dictionary[i])"],"metadata":{"id":"A0aX3Gsn0pLJ","executionInfo":{"status":"ok","timestamp":1652234263081,"user_tz":-420,"elapsed":731,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2388f744-44a2-47e6-f09f-fba664ba5d80"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["bali\n","\n"]}]},{"cell_type":"code","source":["tf.saved_model.save(new_model, \"/content/drive/Shareddrives/_PercobaanKaenova/NER/v3/saved_model\")"],"metadata":{"id":"2bpoXwKNMuQT","executionInfo":{"status":"ok","timestamp":1652234279513,"user_tz":-420,"elapsed":14932,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"db0acd29-b3f9-494f-917a-198ba13f59e4"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/Shareddrives/_PercobaanKaenova/NER/v3/saved_model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/Shareddrives/_PercobaanKaenova/NER/v3/saved_model/assets\n"]}]},{"cell_type":"code","source":["# May not use the model because of availability of the dataset"],"metadata":{"id":"8p2Qi_Ru1WKb","executionInfo":{"status":"ok","timestamp":1652234997601,"user_tz":-420,"elapsed":499,"user":{"displayName":"Kaenova Mahendra","userId":"02905267376027133872"}}},"execution_count":72,"outputs":[]}]}