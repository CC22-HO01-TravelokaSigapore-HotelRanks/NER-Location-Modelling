{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Modelling.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":43,"metadata":{"id":"28cNFoz9YCoD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653030073753,"user_tz":-420,"elapsed":6152,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"0311e406-26e3-405b-b913-d7ec946c6225"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# reference\n","# https://confusedcoders.com/data-science/deep-learning/how-to-build-deep-neural-network-for-custom-ner-with-keras\n","# https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n","# https://www.aitimejournal.com/@akshay.chavan/complete-tutorial-on-named-entity-recognition-ner-using-python-and-keras"],"metadata":{"id":"Tf_Z5-HgYHbC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow tensorflow_text pandas numpy tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWEx_jqbZBx3","executionInfo":{"status":"ok","timestamp":1653028983309,"user_tz":-420,"elapsed":42335,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"0b6c4532-efca-404f-a142-3a530e39e12f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0+zzzcolab20220506162203)\n","Collecting tensorflow_text\n","  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[K     |████████████████████████████████| 4.6 MB 28.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 62.7 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[K     |████████████████████████████████| 511.7 MB 4.5 kB/s \n","\u001b[?25hCollecting flatbuffers>=1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","INFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow_text\n","  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 45.4 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Installing collected packages: tf-estimator-nightly, tensorflow-text\n","Successfully installed tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import tensorflow_text as tf_text\n","import tensorflow as tf\n","# import tensorflow_addons as tfa\n","import numpy as np\n","from tqdm import tqdm\n","import sklearn.model_selection"],"metadata":{"id":"2ulTtP5gYgZo","executionInfo":{"status":"ok","timestamp":1653030081647,"user_tz":-420,"elapsed":3,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# MODEL PARAMS\n","vocab_size = 25000\n","sequence_length = 256"],"metadata":{"id":"5DoToffIbu16","executionInfo":{"status":"ok","timestamp":1653030081648,"user_tz":-420,"elapsed":3,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["Load Data and Prepare"],"metadata":{"id":"rTHXYA67ZGbF"}},{"cell_type":"code","source":["from typing import List\n","\n","def tag_normalize(x: List[int]):\n","  # This will pad the tag to the sequence length\n","  # If the original tag is more than sequence length, it will be turnicate\n","  if len(x) > sequence_length:\n","    return x[:256]\n","  \n","  differences = sequence_length - len(x)\n","  zero_pad = [0 for _ in range(differences)]\n","  x = x + zero_pad\n","  return x"],"metadata":{"id":"Nyk9_am5ddhq","executionInfo":{"status":"ok","timestamp":1653030085875,"user_tz":-420,"elapsed":987,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["!gdown 1piwUH_CpsYyqwpLWQKo5UTnvZk8NlYMG"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHdNPCyd6IzK","executionInfo":{"status":"ok","timestamp":1653029418985,"user_tz":-420,"elapsed":3276,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"c217a438-2f35-4bb1-f6f9-844bb24a9556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1piwUH_CpsYyqwpLWQKo5UTnvZk8NlYMG\n","To: /content/ner_location.csv\n","100% 6.54M/6.54M [00:00<00:00, 22.5MB/s]\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/ner_location.csv\")\n","df['word'] = df['word'].apply(eval) # we need to do this, because we stored this as a list\n","df['tag'] = df['tag'].apply(eval) # we need to do this, because we stored this as a list\n","df[\"sentence\"] = df['word'].apply(lambda x: \" \".join(x))\n","df[\"tag_normal\"] = df['tag'].apply(tag_normalize)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Nch2NISeYmex","executionInfo":{"status":"ok","timestamp":1653030091375,"user_tz":-420,"elapsed":4246,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"f93b49d6-f527-43a6-dc09-f56666d1aeb0"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    word  \\\n","0      [thousands, of, demonstrators, have, marched, ...   \n","1      [helicopter, gunships, saturday, pounded, mili...   \n","2      [un, relief, coordinator, jan, egeland, said, ...   \n","3      [mr, egeland, said, the, latest, figures, show...   \n","4      [he, said, last, week, s, tsunami, and, the, m...   \n","...                                                  ...   \n","24404  [in, an, opinion, piece, in, the, washington, ...   \n","24405  [president, bush, last, week, confirmed, he, s...   \n","24406  [iran, s, elite, security, forces, are, warnin...   \n","24407  [opposition, activists, have, called, for, pro...   \n","24408  [following, iran, s, disputed, june, elections...   \n","\n","                                                     tag  \\\n","0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n","1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n","2      [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n","3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","...                                                  ...   \n","24404  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24405  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24406  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24407  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","24408  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","                                                sentence  \\\n","0      thousands of demonstrators have marched throug...   \n","1      helicopter gunships saturday pounded militant ...   \n","2      un relief coordinator jan egeland said sunday ...   \n","3      mr egeland said the latest figures show millio...   \n","4      he said last week s tsunami and the massive un...   \n","...                                                  ...   \n","24404  in an opinion piece in the washington post fri...   \n","24405  president bush last week confirmed he secretly...   \n","24406  iran s elite security forces are warning oppos...   \n","24407  opposition activists have called for protests ...   \n","24408  following iran s disputed june elections right...   \n","\n","                                              tag_normal  \n","0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n","1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n","2      [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n","3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","...                                                  ...  \n","24404  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24405  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24406  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24407  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","24408  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","\n","[24409 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-7bf3ee4d-b239-4cc9-9c3e-7ddcca4475dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>tag</th>\n","      <th>sentence</th>\n","      <th>tag_normal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[thousands, of, demonstrators, have, marched, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n","      <td>thousands of demonstrators have marched throug...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[helicopter, gunships, saturday, pounded, mili...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>helicopter gunships saturday pounded militant ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[un, relief, coordinator, jan, egeland, said, ...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>un relief coordinator jan egeland said sunday ...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[mr, egeland, said, the, latest, figures, show...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>mr egeland said the latest figures show millio...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[he, said, last, week, s, tsunami, and, the, m...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>he said last week s tsunami and the massive un...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24404</th>\n","      <td>[in, an, opinion, piece, in, the, washington, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>in an opinion piece in the washington post fri...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24405</th>\n","      <td>[president, bush, last, week, confirmed, he, s...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>president bush last week confirmed he secretly...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24406</th>\n","      <td>[iran, s, elite, security, forces, are, warnin...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>iran s elite security forces are warning oppos...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24407</th>\n","      <td>[opposition, activists, have, called, for, pro...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>opposition activists have called for protests ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24408</th>\n","      <td>[following, iran, s, disputed, june, elections...</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>following iran s disputed june elections right...</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>24409 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bf3ee4d-b239-4cc9-9c3e-7ddcca4475dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7bf3ee4d-b239-4cc9-9c3e-7ddcca4475dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7bf3ee4d-b239-4cc9-9c3e-7ddcca4475dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(df[[\"word\", \"sentence\"]], df[\"tag\"], test_size=0.1, random_state=2022)"],"metadata":{"id":"LqidbSZzCHXM","executionInfo":{"status":"ok","timestamp":1653030091944,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# Sanity check on tag_normal\n","for i in range(len(df)):\n","  interest = df[\"tag_normal\"].iloc[i]\n","  if len(interest) != sequence_length:\n","    print(f\"Found wrong length on {i}\")"],"metadata":{"id":"_0s4umoGf0WN","executionInfo":{"status":"ok","timestamp":1653030094272,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Combine all words into one corpus\n","CORPUS = \" \".join(df[\"sentence\"])"],"metadata":{"id":"GSf5luN2bJCx","executionInfo":{"status":"ok","timestamp":1653030094814,"user_tz":-420,"elapsed":1,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Preprocessed train\n","a = X_train[\"word\"].to_list()\n","b = y_train.to_list()\n","word_combine_train = [j for i in a for j in i]\n","tag_combine_train = [j for i in b for j in i]\n","print(\"Train Combined:\")\n","print(len(word_combine_train))\n","print(len(tag_combine_train))\n","\n","\n","a = X_test[\"word\"].to_list()\n","b = y_test.to_list()\n","word_combine_test = [j for i in a for j in i]\n","tag_combine_test = [j for i in b for j in i]\n","print(len(word_combine_test))\n","print(len(tag_combine_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFRp2ZwIoZyB","executionInfo":{"status":"ok","timestamp":1653030096272,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"06caed06-2858-47e2-923b-471a51a532a2"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Combined:\n","474555\n","474555\n","52591\n","52591\n"]}]},{"cell_type":"markdown","source":["Create Text Vectorizer Layer (Preprocessing Layer)   \n","This convert raw strings into number"],"metadata":{"id":"khZZbdOOb8EH"}},{"cell_type":"code","source":["tf.keras.backend.clear_session()"],"metadata":{"id":"JsSmmCu3jwUB","executionInfo":{"status":"ok","timestamp":1653031662758,"user_tz":-420,"elapsed":504,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["vectorize_layer = tf.keras.layers.TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)"],"metadata":{"id":"yYYrzIzzb51C","executionInfo":{"status":"ok","timestamp":1653031662758,"user_tz":-420,"elapsed":3,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["vectorize_layer.adapt([CORPUS])"],"metadata":{"id":"-glityUZcPAX","executionInfo":{"status":"ok","timestamp":1653031663258,"user_tz":-420,"elapsed":503,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b462ee1b-35af-4f68-833a-686579fc9316"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:5 out of the last 5 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f7e163f7d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f7e163f7d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"code","source":["example = df['sentence'].iloc[1]\n","print(f\"Example: {example}\")\n","print(vectorize_layer(example))\n","print(np.array(df['tag_normal'].iloc[1]).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxzHOHWycXPo","executionInfo":{"status":"ok","timestamp":1653031663258,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"b9bcf363-c0d6-4a32-db99-5b6022f56b2e"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["Example: helicopter gunships saturday pounded militant hideouts in the orakzai tribal region where many taliban militants are believed to have fled to avoid an earlier military offensive in nearby south waziristan\n","tf.Tensor(\n","[1067 4236   98 3554  254 3774    3    2 2779  556  119  149  313  408\n","  105   33  741    5   16  786    5 1538   21  140   44  565    3 1218\n","   75  869    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0], shape=(256,), dtype=int64)\n","(256,)\n"]}]},{"cell_type":"markdown","source":["Modelling  \n","1. Text Vectorizer\n","2. Embedding\n","3. BiLSTM\n","4. LSTM\n","5. Dense (sequence_length)"],"metadata":{"id":"W2M4WDbzjlLi"}},{"cell_type":"code","source":["def create_model(train: bool):\n","  input = tf.keras.layers.Input(shape=(1), dtype=tf.string)\n","  x = vectorize_layer(input)\n","  x = tf.keras.layers.Embedding(vocab_size, 256)(x)\n","  x = tf.keras.layers.Dropout(0.5)(x, training=train)\n","  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True), merge_mode = 'concat')(x)\n","  x = tf.keras.layers.BatchNormalization()(x, training=train)\n","  x = tf.keras.layers.Dropout(0.3)(x, training=train)\n","  x = tf.keras.layers.LSTM(256, return_sequences=True)(x)\n","  x = tf.keras.layers.BatchNormalization()(x, training=train)\n","  x = tf.keras.layers.Dropout(0.3)(x, training=train)\n","  output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2, activation=\"softmax\", kernel_initializer='he_normal'))(x)\n","\n","  model = tf.keras.Model(input, output)\n","  optimizer = tf.keras.optimizers.Adam()\n","  loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n","  return model, optimizer, loss_func\n","\n","model, optimizer, loss_func = create_model(True)"],"metadata":{"id":"CidKYKJKjztg","executionInfo":{"status":"ok","timestamp":1653031667975,"user_tz":-420,"elapsed":3190,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3utn0ldj9uA","executionInfo":{"status":"ok","timestamp":1653031667975,"user_tz":-420,"elapsed":12,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"7c9a7dd5-55fe-4cd3-af88-6f523f6b2397"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization (TextVec  (None, 256)              0         \n"," torization)                                                     \n","                                                                 \n"," embedding (Embedding)       (None, 256, 256)          6400000   \n","                                                                 \n"," dropout (Dropout)           (None, 256, 256)          0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 256, 512)         1050624   \n"," l)                                                              \n","                                                                 \n"," batch_normalization (BatchN  (None, 256, 512)         2048      \n"," ormalization)                                                   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256, 512)          0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 256, 256)          787456    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 256, 256)         1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256, 256)          0         \n","                                                                 \n"," time_distributed (TimeDistr  (None, 256, 2)           514       \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 8,241,666\n","Trainable params: 8,240,130\n","Non-trainable params: 1,536\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# # Model Save and Loading Check\n","# model.save(\"/content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/test\")\n","# model = tf.keras.models.load_model(\"/content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/test\")\n","# model.predict([\"test\"])"],"metadata":{"id":"LDOGlo7BO2iO","executionInfo":{"status":"ok","timestamp":1653031668675,"user_tz":-420,"elapsed":1,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":["Train"],"metadata":{"id":"-AtzIwojvNsM"}},{"cell_type":"code","source":["batch_size = 64 # Every 64 data we train it\n","epochs = 3"],"metadata":{"id":"ybJyeDmTvWQL","executionInfo":{"status":"ok","timestamp":1653031670135,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["def train(model: tf.keras.Model):\n","  print(\"Model Training\")\n","  # Sliding window\n","  num_word = len(word_combine_train)\n","  \n","  x_batch = []\n","  y_batch = []\n","\n","  p_bar = tqdm(range(num_word - (num_word % sequence_length + sequence_length)))\n","  for j in p_bar:\n","    start_idx = j\n","    end_idx = j + sequence_length\n","\n","    x_prepare = word_combine_train[start_idx : end_idx] \n","    y_prepare = tag_combine_train[start_idx : end_idx] \n","\n","    x_batch.append(\" \".join(x_prepare))\n","    y_batch.append(y_prepare)\n","\n","    if len(x_batch) % batch_size == 0:\n","      x_feed = tf.convert_to_tensor(x_batch)\n","      y_feed = tf.convert_to_tensor(y_batch)\n","      \n","      with tf.GradientTape() as tape:\n","        # Forward pass\n","        y_pred = model(x_feed)\n","\n","        loss = loss_func(y_feed, y_pred)\n","        pred = tf.math.argmax(y_pred, axis=2)\n","        acc = tf.reduce_mean(tf.keras.metrics.binary_accuracy(y_feed, tf.cast(pred, dtype=tf.int32)))\n","\n","      p_bar.set_postfix({\n","          \"loss\" : loss,\n","          \"acc\": acc\n","      })\n","      \n","      # Backprop\n","      grad = tape.gradient(loss, model.trainable_weights)\n","      optimizer.apply_gradients(zip(grad, model.trainable_weights))\n","\n","      x_batch = []\n","      y_batch = []\n","\n","  return model\n","\n","def test(model: tf.keras.Model):\n","  print(\"Model Validation\")\n","  # Sliding window\n","  num_word = len(word_combine_test)\n","  \n","  x_batch = []\n","  y_batch = []\n","  total_acc = []\n","  total_loss = []\n","\n","  p_bar = tqdm(range(num_word - (num_word % sequence_length + sequence_length)))\n","  for j in p_bar:\n","    start_idx = j\n","    end_idx = j + sequence_length\n","\n","    x_prepare = word_combine_test[start_idx : end_idx] \n","    y_prepare = tag_combine_test[start_idx : end_idx] \n","\n","    x_batch.append(\" \".join(x_prepare))\n","    y_batch.append(y_prepare)\n","\n","    if len(x_batch) % batch_size == 0:\n","      x_feed = tf.convert_to_tensor(x_batch)\n","      y_feed = tf.convert_to_tensor(y_batch)\n","      \n","      # Forward pass\n","      y_pred = model(x_feed)\n","\n","      total_loss.append(loss_func(y_feed, y_pred))\n","      pred = tf.math.argmax(y_pred, axis=2)\n","      total_acc.append(tf.reduce_mean(tf.keras.metrics.binary_accuracy(y_feed, tf.cast(pred, dtype=tf.int32))))\n","\n","      x_batch = []\n","      y_batch = []\n","\n","      p_bar.set_postfix({\n","          \"loss\" : tf.reduce_mean(total_loss),\n","          \"acc\": tf.reduce_mean(total_acc)\n","      })"],"metadata":{"id":"SprhIfLhEgll","executionInfo":{"status":"ok","timestamp":1653031670136,"user_tz":-420,"elapsed":2,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","for i in range(epochs):\n","  print(f\"Epochs: {i}\")\n","  # Train\n","  model = train(model)\n","\n","  # Validation\n","  new_model, _, _ = create_model(False)\n","  new_model.set_weights(model.get_weights())\n","  test(new_model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6ABfPHDvsts","executionInfo":{"status":"ok","timestamp":1653034442260,"user_tz":-420,"elapsed":2771421,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"e2646711-eb13-44d2-a216-4aac068a8c26"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Epochs: 0\n","Model Training\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 474112/474112 [14:44<00:00, 536.06it/s, loss=tf.Tensor(0.13223135, shape=(), dtype=float32), acc=tf.Tensor(0.94750977, shape=(), dtype=float32)]\n"]},{"output_type":"stream","name":"stdout","text":["Model Validation\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 52224/52224 [00:44<00:00, 1177.46it/s, loss=tf.Tensor(0.16476706, shape=(), dtype=float32), acc=tf.Tensor(0.9317308, shape=(), dtype=float32)]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1\n","Model Training\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 474112/474112 [14:36<00:00, 540.71it/s, loss=tf.Tensor(0.111857176, shape=(), dtype=float32), acc=tf.Tensor(0.95806885, shape=(), dtype=float32)]\n"]},{"output_type":"stream","name":"stdout","text":["Model Validation\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 52224/52224 [00:43<00:00, 1193.54it/s, loss=tf.Tensor(0.1550283, shape=(), dtype=float32), acc=tf.Tensor(0.93654984, shape=(), dtype=float32)]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2\n","Model Training\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 474112/474112 [14:35<00:00, 541.80it/s, loss=tf.Tensor(0.075076036, shape=(), dtype=float32), acc=tf.Tensor(0.9694824, shape=(), dtype=float32)]\n"]},{"output_type":"stream","name":"stdout","text":["Model Validation\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 52224/52224 [00:43<00:00, 1192.19it/s, loss=tf.Tensor(0.1547095, shape=(), dtype=float32), acc=tf.Tensor(0.9362086, shape=(), dtype=float32)]\n"]}]},{"cell_type":"code","source":["# Transfer weight\n","new_model, _, _ = create_model(False)\n","new_model.set_weights(model.get_weights())"],"metadata":{"id":"ICU93fTF6wfQ","executionInfo":{"status":"ok","timestamp":1653034444115,"user_tz":-420,"elapsed":1859,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["text = \"hotel in bali\""],"metadata":{"id":"UbIley9J09m-","executionInfo":{"status":"ok","timestamp":1653034444116,"user_tz":-420,"elapsed":5,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["prediction = new_model.predict([text])[0]\n","pred_converted = tf.math.argmax(prediction, axis=1)\n","def get_idx(prediction):\n","  idx = []\n","  for i in range(len(prediction)):\n","    if prediction[i] == 1:\n","      idx.append(i)\n","  return idx\n","\n","index_one = get_idx(pred_converted)\n","\n","text_vectorizator = new_model.get_layer(\"text_vectorization\")\n","dictionary = text_vectorizator.get_vocabulary()\n","vectorized = text_vectorizator([text])[0]\n","attention = []\n","for i in index_one:\n","  attention.append(vectorized[i])\n","for i in attention:\n","  print(dictionary[i])"],"metadata":{"id":"A0aX3Gsn0pLJ","executionInfo":{"status":"ok","timestamp":1653034445326,"user_tz":-420,"elapsed":1215,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8cc573a4-20df-4b35-80bd-a1570f77a776"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7e377ab170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7e377ab170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["bali\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]}]},{"cell_type":"code","source":["new_model.save(\"/content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/v3/saved_model\")"],"metadata":{"id":"2bpoXwKNMuQT","executionInfo":{"status":"ok","timestamp":1653034460675,"user_tz":-420,"elapsed":15355,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"80717db0-5afc-4a0b-ab98-6706e21a3a46"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_18_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/v3/saved_model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/v3/saved_model/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7e16307a90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7e377fea10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7e377ec8d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}]},{"cell_type":"code","source":["# May not use the model because of availability of the dataset"],"metadata":{"id":"8p2Qi_Ru1WKb","executionInfo":{"status":"ok","timestamp":1653034460675,"user_tz":-420,"elapsed":10,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["Testing Save Model"],"metadata":{"id":"v6NxxMVTNEOd"}},{"cell_type":"code","source":["import pandas as pd\n","import tensorflow_text as tf_text\n","import tensorflow as tf\n","# import tensorflow_addons as tfa\n","import numpy as np"],"metadata":{"id":"SxTolUWCNG3X","executionInfo":{"status":"ok","timestamp":1653034460675,"user_tz":-420,"elapsed":9,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["saved_model_path = \"/content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/v3/saved_model\" # The last one should be \"/saved_model\"\n","out_zip_path = \"/content/drive/Shareddrives/CapBatu/ML Divsion/Named Entity Recognition Location/model/v3/saved_model.zip\" # With .zip extension"],"metadata":{"id":"C8Xwl3F-NOKY","executionInfo":{"status":"ok","timestamp":1653034460676,"user_tz":-420,"elapsed":10,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["def get_idx(prediction):\n","  idx = []\n","  for i in range(len(prediction)):\n","    if prediction[i] == 1:\n","      idx.append(i)\n","  return idx\n"],"metadata":{"id":"PHcmjUC2SS_A","executionInfo":{"status":"ok","timestamp":1653034460676,"user_tz":-420,"elapsed":9,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.load_model(saved_model_path)\n","text_vectorizator = model.get_layer(\"text_vectorization\")\n","word_dictionary = text_vectorizator.get_vocabulary()\n","\n","prediction = model.predict([\"hotel in bali\"])[0]\n","pred_converted = tf.math.argmax(prediction, axis=1)\n","index_one = get_idx(pred_converted)\n","\n","attention = []\n","for i in index_one:\n","  attention.append(vectorized[i])\n","for i in attention:\n","  if len(dictionary[i].strip()) != 0: \n","    print(dictionary[i])"],"metadata":{"id":"cjM63OGYNZY5","executionInfo":{"status":"ok","timestamp":1653034471662,"user_tz":-420,"elapsed":10995,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d84f88c4-07e2-4cef-c256-8d08b3f8d159"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["bali\n"]}]},{"cell_type":"code","source":["!cp -r \"{saved_model_path}\" \"./\" && zip -Z bzip2 -r \"{out_zip_path}\" \"./saved_model\" && rm -fr \"saved_model\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P16VvdsOSy6w","executionInfo":{"status":"ok","timestamp":1653034477229,"user_tz":-420,"elapsed":5570,"user":{"displayName":"Kaenova Mahendra Auditama M2012F1247","userId":"11731667220549724114"}},"outputId":"d8b24e97-ea4e-4d73-ad0f-ee9585134bbb"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: saved_model/ (stored 0%)\n","  adding: saved_model/keras_metadata.pb (bzipped 91%)\n","  adding: saved_model/variables/ (stored 0%)\n","  adding: saved_model/variables/variables.index (bzipped 48%)\n","  adding: saved_model/variables/variables.data-00000-of-00001 (bzipped 6%)\n","  adding: saved_model/saved_model.pb (bzipped 94%)\n","  adding: saved_model/assets/ (stored 0%)\n"]}]}]}